{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "7CWFQNMtYxFP",
    "outputId": "9c9728b9-e97a-4dd0-9a56-ab058967ea28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rawpy in /usr/local/lib/python3.6/site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from rawpy) (1.15.4)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrBY_uHZF4da"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as sl\n",
    "import rawpy\n",
    "import glob\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zK-BDOswGdBH"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1WQy6i0Ghal"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    input_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
    "    generated_image = tf.placeholder(tf.float32, [None, None, None, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPVtGNjUIWgo"
   },
   "source": [
    "**custom layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxANBEedIULY"
   },
   "outputs": [],
   "source": [
    "def upsample_and_concat(c1, c2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    dcf = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    dc = tf.nn.conv2d_transpose(c1, dcf, tf.shape(c2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    output = tf.concat([dc, c2], 3)\n",
    "    output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7y1dNOpXnuFL"
   },
   "source": [
    "**custom activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdQk73FPnxcB"
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return tf.maximum(x * 0.2, x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYsN9toMG9vx"
   },
   "source": [
    "**Network**\n",
    "\n",
    "How do we justify this complicated architecture ? Taken from github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "id": "PA4iUtS-GzDm",
    "outputId": "b547d3ee-1899-4999-af07-0e315749b40f"
   },
   "outputs": [],
   "source": [
    "# Unit 1\n",
    "with tf.device('/device:GPU:0'):\n",
    "    c1 = sl.conv2d(input_image, 32,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c1 = sl.conv2d(c1, 32,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    p1 = sl.max_pool2d(c1, [2,2], padding='SAME')\n",
    "# Unit 2\n",
    "    c2 = sl.conv2d(p1, 64,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c2 = sl.conv2d(c2, 64,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    p2 = sl.max_pool2d(c2, [2,2], padding='SAME')\n",
    "# Unit 3\n",
    "    c3 = sl.conv2d(p2, 128,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c3 = sl.conv2d(c3, 128,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    p3 = sl.max_pool2d(c3, [2,2], padding='SAME')\n",
    "# Unit 4\n",
    "    c4 = sl.conv2d(p3, 256,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c4 = sl.conv2d(c4, 256,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    p4 = sl.max_pool2d(c4, [2,2], padding='SAME')\n",
    "# Unit 5\n",
    "    c5 = sl.conv2d(p4, 512,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c5 = sl.conv2d(c5, 512,[3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "# Unit 6\n",
    "    uc6 = upsample_and_concat(c5,c4,256,512)\n",
    "    c6 = sl.conv2d(uc6, 256, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c6 = sl.conv2d(c6, 256, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "# Unit 7\n",
    "    uc7 = upsample_and_concat(c6,c3,128,256)\n",
    "    c7 = sl.conv2d(uc7, 128, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c7 = sl.conv2d(c7, 128, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "# Unit 8\n",
    "    uc8 = upsample_and_concat(c7,c2,64,128)\n",
    "    c8 = sl.conv2d(uc8, 64, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c8 = sl.conv2d(c8, 64, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "# Unit 9\n",
    "    uc9 = upsample_and_concat(c8,c1,32,64)\n",
    "    c9 = sl.conv2d(uc9, 32, [3,3], activation_fn=leaky_relu, weights_regularizer=sl.l1_regularizer(0.05), biases_regularizer=sl.l1_regularizer(0.05))\n",
    "    c9 = sl.conv2d(c9, 32, [3,3], activation_fn=leaky_relu)\n",
    "# Final Unit\n",
    "    c10 = sl.conv2d(c9, 12, [1,1], activation_fn=None)\n",
    "    output_image = tf.depth_to_space(c10,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wc29yCY1G9GP"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    loss = tf.reduce_mean(tf.abs(output_image - generated_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXfQKw0SKTE6"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001, ).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAzOsktaKqPS"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RplIaU7NE1s"
   },
   "outputs": [],
   "source": [
    "input_image_dir = './Sony/short/'\n",
    "generated_image_dir = './Sony/long/'\n",
    "result_dir = './Result/'\n",
    "train_ids = [int(os.path.basename(x)[0:5]) for x in glob.glob(generated_image_dir + '0*.ARW')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2lRIvTEk6P0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuZZd2Q3XdKM"
   },
   "source": [
    "**Converting Bayer image to 4 channel format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8XL1hrzXizz"
   },
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing training lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svK6N2vDZmHM"
   },
   "outputs": [],
   "source": [
    "generated_images = [None] * 6000\n",
    "input_images = {}\n",
    "input_images['300'] = [None] * len(train_ids)\n",
    "input_images['250'] = [None] * len(train_ids)\n",
    "input_images['100'] = [None] * len(train_ids)\n",
    "global_loss = np.zeros((5000, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restoring training progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svK6N2vDZmHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my-test-model9l1.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"my-test-model9l1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1215
    },
    "colab_type": "code",
    "id": "rP7DHfxdK10s",
    "outputId": "647e7882-2299-42f7-d133-2ec0b44a4bb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: This function is deprecated. Please call randint(0, 0 + 1) instead\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: This function is deprecated. Please call randint(0, 2 + 1) instead\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009158397955819964\n",
      "Epoch: 1\n",
      "Loss: 0.0009281924814917148\n",
      "Epoch: 2\n",
      "Loss: 0.0008950681924819946\n",
      "Epoch: 3\n",
      "Loss: 0.0009448589602485299\n",
      "Epoch: 4\n",
      "Loss: 0.0009320997546426952\n",
      "Epoch: 5\n",
      "Loss: 0.0009235549416393041\n",
      "Epoch: 6\n",
      "Loss: 0.0009123854858800769\n",
      "Epoch: 7\n",
      "Loss: 0.0009289742384105921\n",
      "Epoch: 8\n",
      "Loss: 0.0009045358910225331\n",
      "Epoch: 9\n",
      "Loss: 0.0008907906048931182\n",
      "Epoch: 10\n",
      "Loss: 0.000973478177562356\n",
      "Epoch: 11\n",
      "Loss: 0.0009071779321879149\n",
      "Epoch: 12\n",
      "Loss: 0.0008936240253038704\n",
      "Epoch: 13\n",
      "Loss: 0.0008895719056017697\n",
      "Epoch: 14\n",
      "Loss: 0.0009252170357853174\n",
      "Epoch: 15\n",
      "Loss: 0.0009624343912117184\n",
      "Epoch: 16\n",
      "Loss: 0.000917024451866746\n",
      "Epoch: 17\n",
      "Loss: 0.0009201737746596337\n",
      "Epoch: 18\n",
      "Loss: 0.0008903963399119675\n",
      "Epoch: 19\n",
      "Loss: 0.0009667909508571028\n",
      "Epoch: 20\n",
      "Loss: 0.0008774201408959925\n",
      "Epoch: 21\n",
      "Loss: 0.0009422293255105615\n",
      "Epoch: 22\n",
      "Loss: 0.0008867347952909768\n",
      "Epoch: 23\n",
      "Loss: 0.0009358933399431407\n",
      "Epoch: 24\n",
      "Loss: 0.0009128739756532014\n",
      "Epoch: 25\n",
      "Loss: 0.0008738707796670497\n",
      "Epoch: 26\n",
      "Loss: 0.0009050069505348802\n",
      "Epoch: 27\n",
      "Loss: 0.0009150470442138612\n",
      "Epoch: 28\n",
      "Loss: 0.0009359033375047147\n",
      "Epoch: 29\n",
      "Loss: 0.0009165462555363774\n",
      "Epoch: 30\n",
      "Loss: 0.0009371876846998929\n",
      "Epoch: 31\n",
      "Loss: 0.0009125873389653861\n",
      "Epoch: 32\n",
      "Loss: 0.0009309166913852096\n",
      "Epoch: 33\n",
      "Loss: 0.0009074870346114039\n",
      "Epoch: 34\n",
      "Loss: 0.0008931253407150507\n",
      "Epoch: 35\n",
      "Loss: 0.0009330008557997644\n",
      "Epoch: 36\n",
      "Loss: 0.0008924054771661758\n",
      "Epoch: 37\n",
      "Loss: 0.0009088646690361201\n",
      "Epoch: 38\n",
      "Loss: 0.0009150876699015498\n",
      "Epoch: 39\n",
      "Loss: 0.0008781404359266162\n",
      "Epoch: 40\n",
      "Loss: 0.0009318678552284837\n",
      "Epoch: 41\n",
      "Loss: 0.0009055282348766923\n",
      "Epoch: 42\n",
      "Loss: 0.0009166028402745723\n",
      "Epoch: 43\n",
      "Loss: 0.0009187231548130512\n",
      "Epoch: 44\n",
      "Loss: 0.0009098260181024671\n",
      "Epoch: 45\n",
      "Loss: 0.0008967764229513705\n",
      "Epoch: 46\n",
      "Loss: 0.0008621388958767056\n",
      "Epoch: 47\n",
      "Loss: 0.0009435020553879439\n",
      "Epoch: 48\n",
      "Loss: 0.0009633334546349943\n",
      "Epoch: 49\n",
      "Loss: 0.0009218352997675539\n",
      "Epoch: 50\n",
      "Loss: 0.000911263133212924\n",
      "Epoch: 51\n",
      "Loss: 0.000873339119926095\n",
      "Epoch: 52\n",
      "Loss: 0.0008987885715439916\n",
      "Epoch: 53\n",
      "Loss: 0.0008907908421009778\n",
      "Epoch: 54\n",
      "Loss: 0.0008896671006456018\n",
      "Epoch: 55\n",
      "Loss: 0.0009148007947020233\n",
      "Epoch: 56\n",
      "Loss: 0.0008804196164943278\n",
      "Epoch: 57\n",
      "Loss: 0.0008980058332905173\n",
      "Epoch: 58\n",
      "Loss: 0.0008815477859228849\n",
      "Epoch: 59\n",
      "Loss: 0.0009435375427827239\n",
      "Epoch: 60\n",
      "Loss: 0.0009329224571585655\n",
      "Epoch: 61\n",
      "Loss: 0.0009239945885725319\n",
      "Epoch: 62\n",
      "Loss: 0.0008940948880277575\n",
      "Epoch: 65\n",
      "Loss: 0.0009048234822228551\n",
      "Epoch: 66\n",
      "Loss: 0.0008601269253529608\n",
      "Epoch: 67\n",
      "Loss: 0.0008916005884297192\n",
      "Epoch: 68\n",
      "Loss: 0.0009255042674951255\n",
      "Epoch: 69\n",
      "Loss: 0.0008991635064594447\n",
      "Epoch: 70\n",
      "Loss: 0.0009124596977606416\n",
      "Epoch: 71\n",
      "Loss: 0.0009024348743259906\n",
      "Epoch: 72\n",
      "Loss: 0.0009334755560383201\n",
      "Epoch: 73\n",
      "Loss: 0.0008870336725376547\n",
      "Epoch: 74\n",
      "Loss: 0.0009247020252980292\n",
      "Epoch: 75\n",
      "Loss: 0.000899698482081294\n",
      "Epoch: 76\n",
      "Loss: 0.0008609334741719067\n",
      "Epoch: 77\n",
      "Loss: 0.0008712375397793949\n",
      "Epoch: 78\n",
      "Loss: 0.0009092481284402311\n",
      "Epoch: 79\n",
      "Loss: 0.00089608538383618\n",
      "Epoch: 80\n",
      "Loss: 0.0008933395629748702\n",
      "Epoch: 81\n",
      "Loss: 0.0008923482897691429\n",
      "Epoch: 82\n",
      "Loss: 0.0009318444263190031\n",
      "Epoch: 83\n",
      "Loss: 0.0009364940579980612\n",
      "Epoch: 84\n",
      "Loss: 0.0009215750018134714\n",
      "Epoch: 85\n",
      "Loss: 0.0009126473110169172\n",
      "Epoch: 86\n",
      "Loss: 0.0009210044645704329\n",
      "Epoch: 87\n",
      "Loss: 0.0009208856618031859\n",
      "Epoch: 88\n",
      "Loss: 0.0008937515895813704\n",
      "Epoch: 89\n",
      "Loss: 0.0009104149718768894\n",
      "Epoch: 90\n",
      "Loss: 0.0009310732813552022\n",
      "Epoch: 91\n",
      "Loss: 0.0008996542248874903\n",
      "Epoch: 92\n",
      "Loss: 0.0008949902891181409\n",
      "Epoch: 93\n",
      "Loss: 0.0008815023865550756\n",
      "Epoch: 94\n",
      "Loss: 0.0008853730713017285\n",
      "Epoch: 95\n",
      "Loss: 0.0008827544231899083\n",
      "Epoch: 96\n",
      "Loss: 0.0009213946707546711\n",
      "Epoch: 97\n",
      "Loss: 0.0009208224823698401\n",
      "Epoch: 98\n",
      "Loss: 0.0009160406090319156\n",
      "Epoch: 99\n",
      "Loss: 0.0009251475824974477\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    for uid in np.random.permutation(len(train_ids)):\n",
    "        # Retrieve Path of image from id\n",
    "        input_files = glob.glob(input_image_dir + '%05d_00*.ARW' % train_ids[uid])\n",
    "        input_path = input_files[np.random.random_integers(0, len(input_files) - 1)]\n",
    "        generated_files = glob.glob(generated_image_dir + '%05d_00*.ARW' % train_ids[uid])\n",
    "        generated_path = generated_files[0]\n",
    "        \n",
    "        in_fn = os.path.basename(input_path)\n",
    "        gt_fn = os.path.basename(generated_path)\n",
    "        in_exposure = float(in_fn[9:-5])\n",
    "        gt_exposure = float(gt_fn[9:-5])\n",
    "        ratio = min(gt_exposure / in_exposure, 300)\n",
    "\n",
    "        # Reading in the file\n",
    "        if input_images[str(ratio)[0:3]][uid] is None:\n",
    "            raw = rawpy.imread(input_path)\n",
    "            input_images[str(ratio)[0:3]][uid] = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "\n",
    "            gt_raw = rawpy.imread(generated_path)\n",
    "            im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            generated_images[uid] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "        \n",
    "        # crop image to 512 x 512 size\n",
    "        H = input_images[str(ratio)[0:3]][uid].shape[1]\n",
    "        W = input_images[str(ratio)[0:3]][uid].shape[2]\n",
    "        xx = np.random.randint(0, W - 512)\n",
    "        yy = np.random.randint(0, H - 512)\n",
    "        input_crop = input_images[str(ratio)[0:3]][uid][:, yy:yy + 512, xx:xx + 512, :]\n",
    "        generated_crop = generated_images[uid][:, yy * 2:yy * 2 + 512 * 2, xx * 2:xx * 2 + 512 * 2, :]\n",
    "        \n",
    "        # Random Flipping to augment data\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "            input_crop = np.flip(input_crop, axis=1)\n",
    "            generated_crop = np.flip(generated_crop, axis=1)\n",
    "        if np.random.randint(2, size=1)[0] == 1:\n",
    "            input_crop = np.flip(input_crop, axis=2)\n",
    "            generated_crop = np.flip(generated_crop, axis=2)\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "            input_crop = np.transpose(input_crop, (0, 2, 1, 3))\n",
    "            generated_crop = np.transpose(generated_crop, (0, 2, 1, 3))\n",
    "        \n",
    "        input_crop = np.minimum(input_crop, 1.0)\n",
    "\n",
    "        # Run image through tensorflow model\n",
    "        _, current_loss, output = sess.run([optimizer, loss, output_image],\n",
    "                                        feed_dict={input_image: input_crop, generated_image: generated_crop})\n",
    "        output = np.minimum(np.maximum(output, 0), 1)\n",
    "        global_loss[uid] = current_loss\n",
    "        gc.collect()\n",
    "    print('Loss: ' + str(np.mean(global_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug70_dZLQYTM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my-test-model10l1.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, './my-test-model10l1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
