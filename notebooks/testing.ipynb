{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "7CWFQNMtYxFP",
    "outputId": "9c9728b9-e97a-4dd0-9a56-ab058967ea28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rawpy in /usr/local/lib/python3.6/site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from rawpy) (1.15.4)\n",
      "\u001b[31mmenpo 0.8.1 has requirement matplotlib<2.0,>=1.4, but you'll have matplotlib 3.0.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement pillow<5.0,>=3.0, but you'll have pillow 5.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mmenpo 0.8.1 has requirement scipy<1.0,>=0.16, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rawpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrBY_uHZF4da"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as sl\n",
    "import rawpy\n",
    "import glob\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zK-BDOswGdBH"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1WQy6i0Ghal"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    input_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
    "    generated_image = tf.placeholder(tf.float32, [None, None, None, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPVtGNjUIWgo"
   },
   "source": [
    "**custom layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qxANBEedIULY"
   },
   "outputs": [],
   "source": [
    "def upsample_and_concat(c1, c2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    dcf = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    dc = tf.nn.conv2d_transpose(c1, dcf, tf.shape(c2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    output = tf.concat([dc, c2], 3)\n",
    "    output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7y1dNOpXnuFL"
   },
   "source": [
    "**custom activation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdQk73FPnxcB"
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return tf.maximum(x * 0.2, x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYsN9toMG9vx"
   },
   "source": [
    "**Network**\n",
    "\n",
    "How do we justify this complicated architecture ? Taken from github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "id": "PA4iUtS-GzDm",
    "outputId": "b547d3ee-1899-4999-af07-0e315749b40f"
   },
   "outputs": [],
   "source": [
    "# Unit 1\n",
    "with tf.device('/device:GPU:0'):\n",
    "    c1 = sl.conv2d(input_image, 32,[3,3], activation_fn=leaky_relu)\n",
    "    c1 = sl.conv2d(c1, 32,[3,3], activation_fn=leaky_relu)\n",
    "    p1 = sl.max_pool2d(c1, [2,2], padding='SAME')\n",
    "# Unit 2\n",
    "    c2 = sl.conv2d(p1, 64,[3,3], activation_fn=leaky_relu)\n",
    "    c2 = sl.conv2d(c2, 64,[3,3], activation_fn=leaky_relu)\n",
    "    p2 = sl.max_pool2d(c2, [2,2], padding='SAME')\n",
    "# Unit 3\n",
    "    c3 = sl.conv2d(p2, 128,[3,3], activation_fn=leaky_relu)\n",
    "    c3 = sl.conv2d(c3, 128,[3,3], activation_fn=leaky_relu)\n",
    "    p3 = sl.max_pool2d(c3, [2,2], padding='SAME')\n",
    "# Unit 4\n",
    "    c4 = sl.conv2d(p3, 256,[3,3], activation_fn=leaky_relu)\n",
    "    c4 = sl.conv2d(c4, 256,[3,3], activation_fn=leaky_relu)\n",
    "    p4 = sl.max_pool2d(c4, [2,2], padding='SAME')\n",
    "# Unit 5\n",
    "    c5 = sl.conv2d(p4, 512,[3,3], activation_fn=leaky_relu)\n",
    "    c5 = sl.conv2d(c5, 512,[3,3], activation_fn=leaky_relu)\n",
    "# Unit 6\n",
    "    uc6 = upsample_and_concat(c5,c4,256,512)\n",
    "    c6 = sl.conv2d(uc6, 256, [3,3], activation_fn=leaky_relu)\n",
    "    c6 = sl.conv2d(c6, 256, [3,3], activation_fn=leaky_relu)\n",
    "# Unit 7\n",
    "    uc7 = upsample_and_concat(c6,c3,128,256)\n",
    "    c7 = sl.conv2d(uc7, 128, [3,3], activation_fn=leaky_relu)\n",
    "    c7 = sl.conv2d(c7, 128, [3,3], activation_fn=leaky_relu)\n",
    "# Unit 8\n",
    "    uc8 = upsample_and_concat(c7,c2,64,128)\n",
    "    c8 = sl.conv2d(uc8, 64, [3,3], activation_fn=leaky_relu)\n",
    "    c8 = sl.conv2d(c8, 64, [3,3], activation_fn=leaky_relu)\n",
    "# Unit 9\n",
    "    uc9 = upsample_and_concat(c8,c1,32,64)\n",
    "    c9 = sl.conv2d(uc9, 32, [3,3], activation_fn=leaky_relu)\n",
    "    c9 = sl.conv2d(c9, 32, [3,3], activation_fn=leaky_relu)\n",
    "# Final Unit\n",
    "    c10 = sl.conv2d(c9, 12, [1,1], activation_fn=None)\n",
    "    output_image = tf.depth_to_space(c10,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wc29yCY1G9GP"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    loss = tf.reduce_mean(tf.abs(output_image - generated_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXfQKw0SKTE6"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAzOsktaKqPS"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RplIaU7NE1s"
   },
   "outputs": [],
   "source": [
    "input_image_dir = './Sony/short/'\n",
    "generated_image_dir = './Sony/long/'\n",
    "result_dir = './Result/'\n",
    "train_ids = [int(os.path.basename(x)[0:5]) for x in glob.glob(generated_image_dir + '1*.ARW')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2lRIvTEk6P0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuZZd2Q3XdKM"
   },
   "source": [
    "**Converting Bayer image to 4 channel format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8XL1hrzXizz"
   },
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    im = np.maximum(im - 512, 0) / (16383 - 512)  # subtract the black level\n",
    "\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing training lists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svK6N2vDZmHM"
   },
   "outputs": [],
   "source": [
    "generated_images = [None] * 6000\n",
    "input_images = {}\n",
    "input_images['300'] = [None] * len(train_ids)\n",
    "input_images['250'] = [None] * len(train_ids)\n",
    "input_images['100'] = [None] * len(train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restoring training progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svK6N2vDZmHM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my-test-model750l1.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"my-test-model750l1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1215
    },
    "colab_type": "code",
    "id": "rP7DHfxdK10s",
    "outputId": "647e7882-2299-42f7-d133-2ec0b44a4bb8"
   },
   "outputs": [],
   "source": [
    "for uid in range(len(train_ids)):\n",
    "    input_path = glob.glob(input_image_dir + '%05d_00*.ARW' % train_ids[uid])[0]\n",
    "    generated_path = glob.glob(generated_image_dir + '%05d_00*.ARW' % train_ids[uid])[0]\n",
    "        \n",
    "    in_fn = os.path.basename(input_path)\n",
    "    gt_fn = os.path.basename(generated_path)\n",
    "    in_exposure = float(in_fn[9:-5])\n",
    "    gt_exposure = float(gt_fn[9:-5])\n",
    "    ratio = min(gt_exposure / in_exposure, 300)\n",
    "\n",
    "    if input_images[str(ratio)[0:3]][uid] is None:\n",
    "        raw = rawpy.imread(input_path)\n",
    "        input_im = np.expand_dims(pack_raw(raw), axis=0) * ratio\n",
    "\n",
    "        gt_raw = rawpy.imread(generated_path)\n",
    "        im = gt_raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        generated_im = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "\n",
    "    input_im = np.minimum(input_im, 1.0)\n",
    "\n",
    "    # Run image through tensorflow model\n",
    "    _, current_loss, output = sess.run([optimizer, loss, output_image],\n",
    "                                        feed_dict={input_image: input_im, generated_image: generated_im})\n",
    "    output = np.minimum(np.maximum(output, 0), 1)\n",
    "    global_loss += current_loss\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07999888822436332"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_loss/len(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
